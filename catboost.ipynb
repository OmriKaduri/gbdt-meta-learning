{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from catboost import Pool, cv, CatBoostClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "import glob\n",
    "from sklearn.model_selection import cross_validate\n",
    "import hyperopt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def fpr_tpr(y_true, y_pred):\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "\n",
    "    fpr = fp / (fp + tn)\n",
    "    tpr = tp / (tp + fn) #Precision\n",
    "    \n",
    "    return fpr, tpr\n",
    "\n",
    "\n",
    "def fpr_tpr_for_threshold(y_true, y_pred_probs, threshold=.5):\n",
    "    n_classes = np.unique(y_true)\n",
    "    num_paires = (len(n_classes) * (len(n_classes) - 1)) // 2\n",
    "    fpr_scores = np.zeros(num_paires)\n",
    "    tpr_scores = np.zeros(num_paires)\n",
    "    for ix, (a, b) in enumerate(combinations(n_classes, 2)): # one vs one\n",
    "        a_mask = y_true == a\n",
    "        b_mask = y_true == b\n",
    "        ab_mask = np.logical_or(a_mask, b_mask)\n",
    "\n",
    "        a_true = a_mask[ab_mask]\n",
    "        b_true = b_mask[ab_mask]\n",
    "\n",
    "        y_pred_a = np.where(y_pred_probs[ab_mask, a] >= threshold, 1, 0)\n",
    "        y_pred_b = np.where(y_pred_probs[ab_mask, b] >= threshold, 1, 0)\n",
    "\n",
    "        fpr_a, tpr_a = fpr_tpr(a_true, y_pred_a)\n",
    "        fpr_b, tpr_b = fpr_tpr(b_true, y_pred_b)\n",
    "        fpr_scores[ix] = (fpr_a + fpr_b) / 2\n",
    "        tpr_scores[ix] = (tpr_a + tpr_b) / 2\n",
    "        \n",
    "    return np.average(fpr_scores), np.average(tpr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_precision_recall_curve(y_true, y_pred_probs):\n",
    "    n_classes = np.unique(y_true)\n",
    "    num_paires = (len(n_classes) * (len(n_classes) - 1)) // 2\n",
    "    ap_scores = np.zeros(num_paires)\n",
    "    \n",
    "    for ix, (a, b) in enumerate(combinations(n_classes, 2)): # one vs one\n",
    "        a_mask = y_true == a\n",
    "        b_mask = y_true == b\n",
    "        ab_mask = np.logical_or(a_mask, b_mask)\n",
    "\n",
    "        a_true = a_mask[ab_mask]\n",
    "        b_true = b_mask[ab_mask]\n",
    "        \n",
    "        a_ap = average_precision_score(a_true, y_pred_probs[ab_mask, a])\n",
    "        b_ap = average_precision_score(b_true, y_pred_probs[ab_mask, b])\n",
    "        ap_scores[ix] = (a_ap + b_ap) / 2\n",
    "        \n",
    "    return np.average(ap_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, X_test, y_test):\n",
    "    infer_start = timer()\n",
    "    test_preds_proba = model.predict_proba(X_test)\n",
    "    test_preds = np.argmax(test_preds_proba, axis=1)\n",
    "    infer_end = timer()\n",
    "    infer_time = infer_end - infer_start #For all dataset\n",
    "    infer_time_per_1000 = (infer_time / X_test.shape[0])*1000\n",
    "\n",
    "    fpr, tpr = fpr_tpr_for_threshold(y_test, test_preds_proba)\n",
    "    is_multiclass = len(np.unique(y_test)) > 2\n",
    "    if is_multiclass:\n",
    "        auc = roc_auc_score(y_test,test_preds_proba, multi_class='ovr', average='macro') \n",
    "        precision = precision_score(y_test, test_preds, average='macro')\n",
    "        pr_curve = multiclass_precision_recall_curve(y_test, test_preds_proba) # Macro avg\n",
    "    else:\n",
    "        test_preds_proba = np.max(test_preds_proba,axis=1)\n",
    "        auc = roc_auc_score(y_test,test_preds_proba)\n",
    "        precision = precision_score(y_test, test_preds)\n",
    "        pr_curve = average_precision_score(y_test, test_preds_proba)\n",
    "        \n",
    "\n",
    "    return {'Accuracy':accuracy_score(y_test, test_preds),\n",
    "            'TPR':tpr, #macro average\n",
    "            'FPR':fpr, #macro average\n",
    "            'Precision': precision,\n",
    "            'AUC': auc,\n",
    "            'PR-Curve': pr_curve,\n",
    "            'Inference_time':infer_time_per_1000\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, precision_score, roc_auc_score, roc_curve\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class HyperoptObjective(object):\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, model, const_params, fit_params):\n",
    "        self.evaluated_count = 0\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.model = model\n",
    "        self.constant_params = const_params\n",
    "        self.fit_params = fit_params\n",
    "        if self.y_train.dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            self.y_train = le.fit_transform(self.y_train)\n",
    "            self.y_test = le.fit_transform(self.y_test)\n",
    "            \n",
    "        \n",
    "    '''\n",
    "    The way that HyperOpt fmin function works, is that on each evaluation \n",
    "    it calls given objective function. \n",
    "    Since we decided to declare our objective as class instead of a function,\n",
    "    we will implement the evaluation logic inside the __call__ method.\n",
    "    '''\n",
    "    def __call__(self, hyper_params):\n",
    "        model = self.model(**hyper_params, **self.constant_params)\n",
    "        fit_start = timer()\n",
    "        model = model.fit(X=self.X_train,y=self.y_train,**self.fit_params)\n",
    "        fit_end = timer()\n",
    "        fit_time = fit_end - fit_start\n",
    "\n",
    "        self.evaluated_count += 1\n",
    "\n",
    "        metrics = evaluate_metrics(model, self.X_test, self.y_test)\n",
    "#         print(\"Inner AUC:\",metrics['AUC'])\n",
    "#         print(\"Inner Accuracy:\",metrics['Accuracy'])\n",
    "\n",
    "        return {\n",
    "                'loss':-metrics['AUC'],\n",
    "                'status':STATUS_OK,\n",
    "                'fit_time':fit_time,\n",
    "                'model':model\n",
    "            }\n",
    "            #NOTE: The negative sign is due to that fact that we optimize for accuracy,\n",
    "              #therefore we want to minimize the negative acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import space_eval\n",
    "\n",
    "def find_best_params(X_train, \n",
    "                     y_train,   \n",
    "                     X_test,\n",
    "                     y_test,\n",
    "                     model,\n",
    "                     const_params, \n",
    "                     parameter_space, \n",
    "                     fit_params={},\n",
    "                     max_evals=25,\n",
    "                    ):\n",
    "    \n",
    "    objective = HyperoptObjective(X_train, y_train, X_test, y_test, model, const_params, \n",
    "                                  fit_params)\n",
    "    '''\n",
    "    HyperOpt Trials object stores details of every iteration. \n",
    "    https://github.com/hyperopt/hyperopt/wiki/FMin#12-attaching-extra-information-via-the-trials-object\n",
    "    '''\n",
    "    trials = hyperopt.Trials()\n",
    "    \n",
    "    '''\n",
    "    Hyperopt fmin function returns only parameters from the search space.\n",
    "    Therefore, before returning best_params\n",
    "    we will merge best_params with the const params, \n",
    "    so we have all parameters in one place for training the best model.\n",
    "    '''\n",
    "    best_params = hyperopt.fmin(\n",
    "        fn=objective,\n",
    "        space=parameter_space,\n",
    "        algo=hyperopt.tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        trials=trials\n",
    "    )\n",
    "    best_params = space_eval(parameter_space, best_params)\n",
    "    best_params.update(const_params)\n",
    "    \n",
    "    return best_params, trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_cv_hyperopt(X,y, n_splits=3):\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    const_params = {\n",
    "        'verbose': False\n",
    "    }\n",
    "    parameter_space = {\n",
    "        'n_estimators': hyperopt.hp.choice('n_estimators', np.arange(50, 250, 25)),\n",
    "        'max_depth': hyperopt.hp.choice('max_depth', np.arange(5, 9)),\n",
    "        'learning_rate': hyperopt.hp.uniform('learning_rate', 0.01, 0.5),\n",
    "    }\n",
    "    best_auc = 0\n",
    "    for index, (tr_ind, test_ind) in enumerate(kf.split(X,y)):\n",
    "#         print(\"Starting {i} fold out of {n} inner folds\".format(i=index,n=n_splits))\n",
    "        \n",
    "        X_train = X.iloc[tr_ind].copy()\n",
    "        y_train = y.iloc[tr_ind].copy()\n",
    "        \n",
    "        X_test = X.iloc[test_ind].copy()\n",
    "        y_test = y.iloc[test_ind].copy()\n",
    "        cat_features = X_train.select_dtypes(include=['object','category']).columns\n",
    "        fit_params = {\n",
    "            'cat_features': cat_features\n",
    "        }\n",
    "\n",
    "        curr_best_params, trials = find_best_params(\n",
    "            X_train, \n",
    "            y_train, \n",
    "            X_test,\n",
    "            y_test,\n",
    "            CatBoostClassifier,\n",
    "            const_params,\n",
    "            parameter_space,\n",
    "            fit_params,\n",
    "            max_evals=50,\n",
    "        )\n",
    "        fnvals = [(t['result']) for t in trials.trials]\n",
    "        params = max(fnvals, key=lambda x: x['loss'])\n",
    "        if -params['loss'] > best_auc:\n",
    "            best_auc = -params['loss']\n",
    "            fit_time = params['fit_time']\n",
    "            best_params = curr_best_params\n",
    "            model = params['model']\n",
    "            trials = trials\n",
    "            \n",
    "    return best_params, trials, fit_time, model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_cv(X, y, results_df, record, n_splits=10):\n",
    "    df = results_df.copy()\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    for index, (tr_ind, tset_ind) in enumerate(kf.split(X, y)):\n",
    "        print(\"Starting {i} fold out of {n} outher folds\".format(i=index,n=n_splits))\n",
    "        \n",
    "        X_train = X.iloc[tr_ind].copy()\n",
    "        y_train = y.iloc[tr_ind].copy()\n",
    "        \n",
    "        X_test = X.iloc[tset_ind].copy()\n",
    "        y_test = y.iloc[tset_ind].copy()\n",
    "        best_params, trials, fit_time, model = inner_cv_hyperopt(X_train,y_train)\n",
    "        best_metrics = evaluate_metrics(model, X_test, y_test)\n",
    "        best_metrics['Training_time'] = fit_time\n",
    "        info = {'CV_fold':index,\n",
    "                'HP_vals':{k: best_params[k] for k in list(best_params)[:3]},\n",
    "                **best_metrics\n",
    "               }\n",
    "        record.update(info)\n",
    "        df = df.append(record, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting on aacute-inflammation - Copy dataset\n",
      "Starting 0 fold out of 10 outher folds\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:12<00:00,  4.13trial/s, best loss: -0.6603174603174604]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:12<00:00,  4.11trial/s, best loss: -0.8181818181818182]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:15<00:00,  3.15trial/s, best loss: -0.7160493827160493]\n",
      "Starting 1 fold out of 10 outher folds\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:13<00:00,  3.61trial/s, best loss: -0.8246753246753247]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:14<00:00,  3.46trial/s, best loss: -0.7894736842105263]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:18<00:00,  2.75trial/s, best loss: -0.7987616099071206]\n",
      "Starting 2 fold out of 10 outher folds\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:15<00:00,  3.16trial/s, best loss: -0.8364197530864198]\n",
      "100%|███████████████████████████████████████████████████████████| 50/50 [00:12<00:00,  3.94trial/s, best loss: -0.6375]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:16<00:00,  2.96trial/s, best loss: -0.9904761904761905]\n",
      "Starting 3 fold out of 10 outher folds\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:13<00:00,  3.76trial/s, best loss: -0.8762541806020067]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:13<00:00,  3.58trial/s, best loss: -0.7870370370370371]\n",
      "100%|███████████████████████████████████████████████████████████| 50/50 [00:12<00:00,  3.99trial/s, best loss: -0.6875]\n",
      "Starting 4 fold out of 10 outher folds\n",
      "100%|█████████████████████████████████████████████████████████| 50/50 [00:13<00:00,  3.62trial/s, best loss: -0.671875]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:11<00:00,  4.22trial/s, best loss: -0.7157190635451505]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:13<00:00,  3.76trial/s, best loss: -0.8142414860681114]\n",
      "Starting 5 fold out of 10 outher folds\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:15<00:00,  3.33trial/s, best loss: -0.6080246913580247]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:12<00:00,  4.11trial/s, best loss: -0.9722222222222222]\n",
      "100%|█████████████████████████████████████████████████████████| 50/50 [00:12<00:00,  4.08trial/s, best loss: -0.678125]\n",
      "Starting 6 fold out of 10 outher folds\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:16<00:00,  3.08trial/s, best loss: -0.8271604938271605]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:15<00:00,  3.13trial/s, best loss: -0.6604938271604939]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:15<00:00,  3.13trial/s, best loss: -0.5416666666666666]\n",
      "Starting 7 fold out of 10 outher folds\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:12<00:00,  4.02trial/s, best loss: -0.7558528428093645]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:12<00:00,  4.04trial/s, best loss: -0.8734567901234569]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:11<00:00,  4.52trial/s, best loss: -0.9015873015873016]\n",
      "Starting 8 fold out of 10 outher folds\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:14<00:00,  3.35trial/s, best loss: -0.6965944272445821]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:18<00:00,  2.64trial/s, best loss: -0.7098765432098766]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:12<00:00,  4.11trial/s, best loss: -0.7305194805194805]\n",
      "Starting 9 fold out of 10 outher folds\n",
      "100%|█████████████████████████████████████████████████████████| 50/50 [00:16<00:00,  3.07trial/s, best loss: -0.934375]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:15<00:00,  3.20trial/s, best loss: -0.6006493506493507]\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:13<00:00,  3.63trial/s, best loss: -0.9015873015873016]\n",
      "Fitting on abalon dataset\n",
      "Starting 0 fold out of 10 outher folds\n",
      " 52%|████████████████████████▍                      | 26/50 [00:40<00:37,  1.57s/trial, best loss: -0.8364575674377015]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-13636b96995b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mresults_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mouter_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mresults_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRESULTS_FILENAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-21b1fcbbebcc>\u001b[0m in \u001b[0;36mouter_cv\u001b[1;34m(X, y, results_df, record, n_splits)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtset_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtset_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mbest_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner_cv_hyperopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mbest_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mbest_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Training_time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-b9a46756463b>\u001b[0m in \u001b[0;36minner_cv_hyperopt\u001b[1;34m(X, y, n_splits)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mparameter_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         )\n\u001b[0;32m     37\u001b[0m         \u001b[0mfnvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-aa816e5e9c92>\u001b[0m in \u001b[0;36mfind_best_params\u001b[1;34m(X_train, y_train, X_test, y_test, model, const_params, parameter_space, fit_params, max_evals)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     )\n\u001b[0;32m     35\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspace_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameter_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\omri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m         )\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\omri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m         )\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\omri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\omri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\omri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    284\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\omri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\omri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             )\n\u001b[1;32m--> 894\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-2e8aa9a5a31d>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, hyper_params)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mfit_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mfit_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_end\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_start\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\omri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   3995\u001b[0m         self._fit(X, y, cat_features, text_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0;32m   3996\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3997\u001b[1;33m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[0;32m   3998\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\omri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1741\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m             )\n\u001b[0;32m   1745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\omri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1230\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1231\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "results_df = pd.DataFrame(columns=['Dataset','Algorithm','CV_fold','HP_vals','Accuracy','TPR','FPR','Precision','AUC','PR-Curve','Training_time','Inference_time'])\n",
    "RESULTS_FILENAME = \"catboost-results.csv\"\n",
    "results_file = Path(RESULTS_FILENAME)\n",
    "if results_file.is_file():\n",
    "    results_df = pd.read_csv(RESULTS_FILENAME)\n",
    "\n",
    "for cls_dataset in glob.glob('classification_datasets/*.csv'): \n",
    "    dataset_name = Path(cls_dataset).stem\n",
    "    if dataset_name in results_df.Dataset.unique():\n",
    "        print(\"Skipping already fitted dataset: {f}\".format(f=dataset_name))\n",
    "        continue\n",
    "    print(\"Fitting on {f} dataset\".format(f=dataset_name))\n",
    "    record = {'Dataset':dataset_name,'Algorithm':'Catboost'}\n",
    "    df = pd.read_csv(cls_dataset)\n",
    "    X = df[df.columns[:-1]]\n",
    "    y = df[df.columns[-1]]\n",
    "    results_df = outer_cv(X,y, results_df,record)\n",
    "    results_df.to_csv(RESULTS_FILENAME,index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
