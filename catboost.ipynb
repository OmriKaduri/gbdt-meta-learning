{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T15:56:39.011902Z",
     "start_time": "2020-08-01T15:56:38.145809Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from catboost import Pool, cv, CatBoostClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import glob\n",
    "from sklearn.model_selection import cross_validate\n",
    "import hyperopt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T15:56:39.022205Z",
     "start_time": "2020-08-01T15:56:39.014144Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def fpr_tpr(y_true, y_pred):\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "\n",
    "    fpr = fp / (fp + tn)\n",
    "    tpr = tp / (tp + fn) #Precision\n",
    "    \n",
    "    return fpr, tpr\n",
    "\n",
    "\n",
    "def fpr_tpr_for_threshold(y_true, y_pred_probs, threshold=.5):\n",
    "    n_classes = np.unique(y_true)\n",
    "    num_paires = (len(n_classes) * (len(n_classes) - 1)) // 2\n",
    "    fpr_scores = np.zeros(num_paires)\n",
    "    tpr_scores = np.zeros(num_paires)\n",
    "    \n",
    "    for ix, (a, b) in enumerate(combinations(n_classes, 2)): # one vs one\n",
    "        a_mask = y_true == a\n",
    "        b_mask = y_true == b\n",
    "        ab_mask = np.logical_or(a_mask, b_mask)\n",
    "\n",
    "        a_true = a_mask[ab_mask]\n",
    "        b_true = b_mask[ab_mask]\n",
    "        y_pred_a = np.where(y_pred_probs[ab_mask, a] >= threshold, 1, 0)\n",
    "        y_pred_b = np.where(y_pred_probs[ab_mask, b] >= threshold, 1, 0)\n",
    "\n",
    "        fpr_a, tpr_a = fpr_tpr(a_true, y_pred_a)\n",
    "        fpr_b, tpr_b = fpr_tpr(b_true, y_pred_b)\n",
    "        fpr_scores[ix] = (fpr_a + fpr_b) / 2\n",
    "        tpr_scores[ix] = (tpr_a + tpr_b) / 2\n",
    "        \n",
    "    return np.average(fpr_scores), np.average(tpr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T15:56:39.039707Z",
     "start_time": "2020-08-01T15:56:39.024487Z"
    }
   },
   "outputs": [],
   "source": [
    "def multiclass_precision_recall_curve(y_true, y_pred_probs):\n",
    "    n_classes = np.unique(y_true)\n",
    "    num_paires = (len(n_classes) * (len(n_classes) - 1)) // 2\n",
    "    ap_scores = np.zeros(num_paires)\n",
    "    \n",
    "    for ix, (a, b) in enumerate(combinations(n_classes, 2)): # one vs one\n",
    "        a_mask = y_true == a\n",
    "        b_mask = y_true == b\n",
    "        ab_mask = np.logical_or(a_mask, b_mask)\n",
    "\n",
    "        a_true = a_mask[ab_mask]\n",
    "        b_true = b_mask[ab_mask]\n",
    "        \n",
    "        a_ap = average_precision_score(a_true, y_pred_probs[ab_mask, a])\n",
    "        b_ap = average_precision_score(b_true, y_pred_probs[ab_mask, b])\n",
    "        ap_scores[ix] = (a_ap + b_ap) / 2\n",
    "        \n",
    "    return np.average(ap_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T15:56:39.050979Z",
     "start_time": "2020-08-01T15:56:39.041604Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, X_test, y_test, is_multiclass):\n",
    "    infer_start = timer()\n",
    "    test_preds_proba = model.predict_proba(X_test)\n",
    "    test_preds = np.argmax(test_preds_proba, axis=1)\n",
    "    infer_end = timer()\n",
    "    infer_time = infer_end - infer_start #For all dataset\n",
    "    infer_time_per_1000 = (infer_time / X_test.shape[0])*1000\n",
    "\n",
    "    fpr, tpr = fpr_tpr_for_threshold(y_test, test_preds_proba)\n",
    "    \n",
    "    \n",
    "    if is_multiclass:\n",
    "        auc = roc_auc_score(y_test,test_preds_proba, multi_class='ovr', average='macro') \n",
    "        precision = precision_score(y_test, test_preds, average='macro')\n",
    "        pr_curve = multiclass_precision_recall_curve(y_test, test_preds_proba) # Macro avg\n",
    "    else:\n",
    "        test_preds_proba = np.max(test_preds_proba,axis=1)\n",
    "        auc = roc_auc_score(y_test,test_preds_proba)\n",
    "        precision = precision_score(y_test, test_preds)\n",
    "        pr_curve = average_precision_score(y_test, test_preds_proba)\n",
    "        \n",
    "\n",
    "    return {'Accuracy':accuracy_score(y_test, test_preds),\n",
    "            'TPR':tpr, #macro average\n",
    "            'FPR':fpr, #macro average\n",
    "            'Precision': precision,\n",
    "            'AUC': auc,\n",
    "            'PR-Curve': pr_curve,\n",
    "            'Inference_time':infer_time_per_1000\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T15:56:39.062515Z",
     "start_time": "2020-08-01T15:56:39.052814Z"
    }
   },
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, precision_score, roc_auc_score, roc_curve\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class HyperoptObjective(object):\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, model, const_params, fit_params):\n",
    "        self.is_multiclass = len(np.unique(y_train)) > 2\n",
    "        self.evaluated_count = 0\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.model = model\n",
    "        self.constant_params = const_params\n",
    "        self.fit_params = fit_params\n",
    "        \n",
    "        if self.y_train.dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            self.y_train = le.fit_transform(self.y_train)\n",
    "            self.y_test = le.fit_transform(self.y_test)\n",
    "            \n",
    "        \n",
    "    '''\n",
    "    The way that HyperOpt fmin function works, is that on each evaluation \n",
    "    it calls given objective function. \n",
    "    Since we decided to declare our objective as class instead of a function,\n",
    "    we will implement the evaluation logic inside the __call__ method.\n",
    "    '''\n",
    "    def __call__(self, hyper_params):\n",
    "        model = self.model(**hyper_params, **self.constant_params)\n",
    "        fit_start = timer()\n",
    "        model = model.fit(X=self.X_train,y=self.y_train,**self.fit_params)\n",
    "        fit_end = timer()\n",
    "        fit_time = fit_end - fit_start\n",
    "\n",
    "        self.evaluated_count += 1\n",
    "\n",
    "        metrics = evaluate_metrics(model, self.X_test, self.y_test, self.is_multiclass)\n",
    "#         print(\"Inner AUC:\",metrics['AUC'])\n",
    "#         print(\"Inner Accuracy:\",metrics['Accuracy'])\n",
    "\n",
    "        return {\n",
    "                'loss':-metrics['AUC'],\n",
    "                'status':STATUS_OK,\n",
    "                'fit_time':fit_time,\n",
    "                'model':model\n",
    "            }\n",
    "            #NOTE: The negative sign is due to that fact that we optimize for accuracy,\n",
    "              #therefore we want to minimize the negative acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T15:56:39.073424Z",
     "start_time": "2020-08-01T15:56:39.064278Z"
    }
   },
   "outputs": [],
   "source": [
    "from hyperopt import space_eval\n",
    "\n",
    "def find_best_params(X_train, \n",
    "                     y_train,   \n",
    "                     X_test,\n",
    "                     y_test,\n",
    "                     model,\n",
    "                     const_params, \n",
    "                     parameter_space, \n",
    "                     fit_params={},\n",
    "                     max_evals=25,\n",
    "                    ):\n",
    "    \n",
    "    objective = HyperoptObjective(X_train, y_train, X_test, y_test, model, const_params, \n",
    "                                  fit_params)\n",
    "    '''\n",
    "    HyperOpt Trials object stores details of every iteration. \n",
    "    https://github.com/hyperopt/hyperopt/wiki/FMin#12-attaching-extra-information-via-the-trials-object\n",
    "    '''\n",
    "    trials = hyperopt.Trials()\n",
    "    \n",
    "    '''\n",
    "    Hyperopt fmin function returns only parameters from the search space.\n",
    "    Therefore, before returning best_params\n",
    "    we will merge best_params with the const params, \n",
    "    so we have all parameters in one place for training the best model.\n",
    "    '''\n",
    "    best_params = hyperopt.fmin(\n",
    "        fn=objective,\n",
    "        space=parameter_space,\n",
    "        algo=hyperopt.tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        trials=trials\n",
    "    )\n",
    "    best_params = space_eval(parameter_space, best_params)\n",
    "    best_params.update(const_params)\n",
    "    \n",
    "    return best_params, trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T15:56:39.085848Z",
     "start_time": "2020-08-01T15:56:39.075456Z"
    }
   },
   "outputs": [],
   "source": [
    "def inner_cv_hyperopt(X,y, n_splits=3):\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "    const_params = {\n",
    "        'verbose': False,\n",
    "        'task_type': \"CPU\"\n",
    "    }\n",
    "    parameter_space = {\n",
    "        'n_estimators': hyperopt.hp.choice('n_estimators', np.arange(50, 250, 25)),\n",
    "        'max_depth': hyperopt.hp.choice('max_depth', np.arange(5, 9)),\n",
    "        'learning_rate': hyperopt.hp.uniform('learning_rate', 0.01, 0.5),\n",
    "    }\n",
    "    best_auc = 0\n",
    "    for index, (tr_ind, test_ind) in enumerate(kf.split(X,y)):\n",
    "#         print(\"Starting {i} fold out of {n} inner folds\".format(i=index,n=n_splits))\n",
    "        \n",
    "        X_train = X.iloc[tr_ind].copy()\n",
    "#         y_train = y.iloc[tr_ind].copy()\n",
    "        y_train = y[tr_ind]\n",
    "        \n",
    "        X_test = X.iloc[test_ind].copy()\n",
    "        y_test = y[test_ind]\n",
    "        cat_features = X_train.select_dtypes(include=['object','category']).columns\n",
    "        fit_params = {\n",
    "            'cat_features': cat_features\n",
    "        }\n",
    "\n",
    "        curr_best_params, trials = find_best_params(\n",
    "            X_train, \n",
    "            y_train, \n",
    "            X_test,\n",
    "            y_test,\n",
    "            CatBoostClassifier,\n",
    "            const_params,\n",
    "            parameter_space,\n",
    "            fit_params,\n",
    "            max_evals=50,\n",
    "        )\n",
    "        fnvals = [(t['result']) for t in trials.trials]\n",
    "        params = max(fnvals, key=lambda x: x['loss'])\n",
    "        if -params['loss'] > best_auc:\n",
    "            best_auc = -params['loss']\n",
    "            fit_time = params['fit_time']\n",
    "            best_params = curr_best_params\n",
    "            model = params['model']\n",
    "            trials = trials\n",
    "            \n",
    "    return best_params, trials, fit_time, model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T15:56:39.096717Z",
     "start_time": "2020-08-01T15:56:39.088096Z"
    }
   },
   "outputs": [],
   "source": [
    "def outer_cv(X, y, results_df, record, n_splits=10):\n",
    "    df = results_df.copy()\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "    is_multiclass = len(np.unique(y)) > 2\n",
    "    \n",
    "    for index, (tr_ind, tset_ind) in enumerate(kf.split(X, y)):\n",
    "        print(\"Starting {i} fold out of {n} outher folds\".format(i=index,n=n_splits))\n",
    "        \n",
    "        X_train = X.iloc[tr_ind].copy()\n",
    "        y_train = y[tr_ind]\n",
    "        \n",
    "        X_test = X.iloc[tset_ind].copy()\n",
    "        y_test = y[tset_ind]\n",
    "        best_params, trials, fit_time, model = inner_cv_hyperopt(X_train,y_train)\n",
    "        best_metrics = evaluate_metrics(model, X_test, y_test, is_multiclass)\n",
    "        best_metrics['Training_time'] = fit_time\n",
    "        info = {'CV_fold':index,\n",
    "                'HP_vals':{k: best_params[k] for k in list(best_params)[:3]},\n",
    "                **best_metrics\n",
    "               }\n",
    "        record.update(info)\n",
    "        df = df.append(record, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-01T15:56:38.161Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting on lung-cancer dataset\n",
      "Starting 0 fold out of 10 outher folds\n",
      "\r",
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:50<00:00,  1.01s/trial, best loss: -0.8988095238095238]\n",
      "100%|██████████| 50/50 [00:41<00:00,  1.22trial/s, best loss: -0.9074074074074074]\n",
      "100%|██████████| 50/50 [00:59<00:00,  1.20s/trial, best loss: -0.9500000000000001]\n",
      "Starting 1 fold out of 10 outher folds\n",
      "  8%|▊         | 4/50 [00:02<00:35,  1.30trial/s, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/50 [00:04<00:46,  1.04s/trial, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:07<00:50,  1.17s/trial, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [00:09<00:56,  1.35s/trial, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [00:09<00:43,  1.07s/trial, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 10/50 [00:11<00:51,  1.28s/trial, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/50 [00:12<00:49,  1.28s/trial, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:14<00:32,  1.11trial/s, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:15<00:23,  1.44trial/s, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 17/50 [00:16<00:22,  1.45trial/s, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:17<00:22,  1.39trial/s, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:23<00:25,  1.01trial/s, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [00:26<00:21,  1.03trial/s, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:30<00:17,  1.01trial/s, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [00:34<00:14,  1.02s/trial, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 37/50 [00:36<00:14,  1.13s/trial, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [00:39<00:13,  1.26s/trial, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [00:41<00:10,  1.19s/trial, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [00:43<00:08,  1.15s/trial, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [00:46<00:06,  1.24s/trial, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [00:48<00:03,  1.18s/trial, best loss: -0.8690476190476191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/anaconda3/envs/hirsch_env/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:51<00:00,  1.02s/trial, best loss: -0.8690476190476191]\n",
      " 26%|██▌       | 13/50 [00:13<00:42,  1.14s/trial, best loss: -0.7037037037037037]"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sklearn import preprocessing\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Dataset','Algorithm','CV_fold','HP_vals','Accuracy','TPR','FPR','Precision','AUC','PR-Curve','Training_time','Inference_time'])\n",
    "RESULTS_FILENAME = \"catboost-results.csv\"\n",
    "results_file = Path(RESULTS_FILENAME)\n",
    "if results_file.is_file():\n",
    "    results_df = pd.read_csv(RESULTS_FILENAME)\n",
    "\n",
    "for cls_dataset in glob.glob('classification_datasets/*.csv')[6:]: \n",
    "    dataset_name = Path(cls_dataset).stem\n",
    "    if dataset_name in results_df.Dataset.unique():\n",
    "        print(\"Skipping already fitted dataset: {f}\".format(f=dataset_name))\n",
    "        continue\n",
    "    print(\"Fitting on {f} dataset\".format(f=dataset_name))\n",
    "    record = {'Dataset':dataset_name,'Algorithm':'Catboost'}\n",
    "    df = pd.read_csv(cls_dataset)\n",
    "    X = df[df.columns[:-1]]\n",
    "    y = df[df.columns[-1]]\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_transformed = le.fit_transform(y)\n",
    "    \n",
    "    results_df = outer_cv(X,y_transformed, results_df,record)\n",
    "    results_df.to_csv(RESULTS_FILENAME,index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
