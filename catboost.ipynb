{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from catboost import Pool, cv, CatBoostClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "import glob\n",
    "from sklearn.model_selection import cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def fpr_tpr(y_true, y_pred):\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "\n",
    "    fpr = fp / (fp + tn)\n",
    "    tpr = tp / (tp + fn) #Precision\n",
    "    \n",
    "    return fpr, tpr\n",
    "\n",
    "\n",
    "def fpr_tpr_for_threshold(y_true, y_pred_probs, threshold=.5):\n",
    "    n_classes = np.unique(y_true)\n",
    "    num_paires = (len(n_classes) * (len(n_classes) - 1)) // 2\n",
    "    fpr_scores = np.zeros(num_paires)\n",
    "    tpr_scores = np.zeros(num_paires)\n",
    "    for ix, (a, b) in enumerate(combinations(n_classes, 2)): # one vs one\n",
    "        a_mask = y_true == a\n",
    "        b_mask = y_true == b\n",
    "        ab_mask = np.logical_or(a_mask, b_mask)\n",
    "\n",
    "        a_true = a_mask[ab_mask]\n",
    "        b_true = b_mask[ab_mask]\n",
    "        y_pred_a = np.where(y_pred_probs[ab_mask, a] >= threshold, 1, 0)\n",
    "        y_pred_b = np.where(y_pred_probs[ab_mask, b] >= threshold, 1, 0)\n",
    "\n",
    "        fpr_a, tpr_a = fpr_tpr(a_true, y_pred_a)\n",
    "        fpr_b, tpr_b = fpr_tpr(b_true, y_pred_b)\n",
    "        fpr_scores[ix] = (fpr_a + fpr_b) / 2\n",
    "        tpr_scores[ix] = (tpr_a + tpr_b) / 2\n",
    "        \n",
    "    return np.average(fpr_scores), np.average(tpr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_precision_recall_curve(y_true, y_pred_probs):\n",
    "    n_classes = np.unique(y_true)\n",
    "    num_paires = (len(n_classes) * (len(n_classes) - 1)) // 2\n",
    "    ap_scores = np.zeros(num_paires)\n",
    "    \n",
    "    for ix, (a, b) in enumerate(combinations(n_classes, 2)): # one vs one\n",
    "        a_mask = y_true == a\n",
    "        b_mask = y_true == b\n",
    "        ab_mask = np.logical_or(a_mask, b_mask)\n",
    "\n",
    "        a_true = a_mask[ab_mask]\n",
    "        b_true = b_mask[ab_mask]\n",
    "        \n",
    "        a_ap = average_precision_score(a_true, y_pred_probs[ab_mask, a])\n",
    "        b_ap = average_precision_score(b_true, y_pred_probs[ab_mask, b])\n",
    "        ap_scores[ix] = (a_ap + b_ap) / 2\n",
    "        \n",
    "    return np.average(ap_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, precision_score, roc_auc_score, roc_curve\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class HyperoptObjective(object):\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, model, const_params, fit_params):\n",
    "        self.evaluated_count = 0\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.model = model\n",
    "        self.constant_params = const_params\n",
    "        self.fit_params = fit_params\n",
    "        \n",
    "    '''\n",
    "    The way that HyperOpt fmin function works, is that on each evaluation \n",
    "    it calls given objective function. \n",
    "    Since we decided to declare our objective as class instead of a function,\n",
    "    we will implement the evaluation logic inside the __call__ method.\n",
    "    '''\n",
    "    def __call__(self, hyper_params):\n",
    "        \n",
    "        model = self.model(**hyper_params, **self.constant_params)\n",
    "        fit_start = timer()\n",
    "        best = model.fit(X=self.X_train,y=self.y_train,**self.fit_params)\n",
    "        fit_end = timer()\n",
    "        fit_time = fit_end - fit_start\n",
    "        infer_start = timer()\n",
    "        test_preds_proba = best.predict_proba(self.X_test)\n",
    "        test_preds = np.argmax(test_preds_proba, axis=1)\n",
    "        infer_end = timer()\n",
    "        infer_time = infer_end - infer_start\n",
    "\n",
    "        test_pool = Pool(data=self.X_test,\n",
    "                  label=self.y_test)\n",
    "        self.evaluated_count += 1\n",
    "        fpr, tpr = fpr_tpr_for_threshold(self.y_test, test_preds_proba)\n",
    "        return {'loss':-accuracy_score(self.y_test, test_preds),\n",
    "                'status':STATUS_OK,\n",
    "                'metrics':{\n",
    "                    'Accuracy':accuracy_score(self.y_test, test_preds),\n",
    "                    'TPR':fpr, #macro average\n",
    "                    'FPR':tpr, #macro average\n",
    "                    'Precision':precision_score(self.y_test, test_preds, average='macro'), \n",
    "                    'AUC':roc_auc_score(self.y_test,test_preds_proba,multi_class='ovo', average='macro'), \n",
    "                    'PR-Curve':multiclass_precision_recall_curve(self.y_test, test_preds_proba ), # Macro avg\n",
    "                    'Training_time':fit_time,\n",
    "                    'Inference_time':infer_time\n",
    "                    }\n",
    "                }\n",
    "                #NOTE: The negative sign is due to that fact that we optimize for accuracy,\n",
    "                          #therefore we want to minimize the negative acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_params(X_train, \n",
    "                     y_train,   \n",
    "                     X_test,\n",
    "                     y_test,\n",
    "                     model,\n",
    "                     const_params, \n",
    "                     parameter_space, \n",
    "                     fit_params={},\n",
    "                     max_evals=25,\n",
    "                     cv_splitter=None,\n",
    "                     cv_scoring=None\n",
    "                    ):\n",
    "    \n",
    "    objective = HyperoptObjective(X_train, y_train, X_test, y_test, model, const_params, \n",
    "                                  fit_params)\n",
    "    '''\n",
    "    HyperOpt Trials object stores details of every iteration. \n",
    "    https://github.com/hyperopt/hyperopt/wiki/FMin#12-attaching-extra-information-via-the-trials-object\n",
    "    '''\n",
    "    trials = hyperopt.Trials()\n",
    "    \n",
    "    '''\n",
    "    Hyperopt fmin function returns only parameters from the search space.\n",
    "    Therefore, before returning best_params\n",
    "    we will merge best_params with the const params, \n",
    "    so we have all parameters in one place for training the best model.\n",
    "    '''\n",
    "    best_params = hyperopt.fmin(\n",
    "        fn=objective,\n",
    "        space=parameter_space,\n",
    "        algo=hyperopt.tpe.suggest,\n",
    "        rstate=np.random.RandomState(seed=42),\n",
    "        max_evals=max_evals,\n",
    "        trials=trials\n",
    "    )\n",
    "      \n",
    "    best_params.update(const_params)\n",
    "    \n",
    "    return best_params, trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "def inner_cv_hyperopt(X,y, n_splits=3):\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    const_params = {\n",
    "        'verbose': False\n",
    "    }\n",
    "    parameter_space = {\n",
    "        'n_estimators': hyperopt.hp.choice('n_estimators', np.arange(50, 250, 25)),\n",
    "        'max_depth': hyperopt.hp.choice('max_depth', np.arange(5, 9)),\n",
    "        'learning_rate': hyperopt.hp.uniform('learning_rate', 0.01, 0.5),\n",
    "    }\n",
    "    best_acc = 0\n",
    "    best_auc = 0\n",
    "    best_precision = 0\n",
    "    for index, (tr_ind, test_ind) in enumerate(kf.split(X,y)):\n",
    "        print(\"Starting {i} fold out of {n} inner folds\".format(i=index,n=n_splits))\n",
    "        \n",
    "        X_train = X.iloc[tr_ind].copy()\n",
    "        y_train = y.iloc[tr_ind].copy()\n",
    "        \n",
    "        X_test = X.iloc[test_ind].copy()\n",
    "        y_test = y.iloc[test_ind].copy()\n",
    "        cat_features = X_train.select_dtypes(include=['object','category']).columns\n",
    "        fit_params = {\n",
    "            'cat_features': cat_features\n",
    "        }\n",
    "\n",
    "        curr_best_params, trials = find_best_params(\n",
    "            X_train, \n",
    "            y_train, \n",
    "            X_test,\n",
    "            y_test,\n",
    "            CatBoostClassifier,\n",
    "            const_params,\n",
    "            parameter_space,\n",
    "            fit_params,\n",
    "            max_evals=2,\n",
    "        )\n",
    "        \n",
    "        fnvals = [(t['result']['metrics']) for t in trials.trials]\n",
    "        params = max(fnvals, key = lambda x: x['Accuracy']) # (accuracy, auc, precision)\n",
    "        if params['Accuracy'] > best_acc:\n",
    "            best_metrics = params\n",
    "            best_params = curr_best_params\n",
    "            trials = trials\n",
    "            \n",
    "    return best_params, best_metrics, trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def outer_cv(X, y, results_df, record, n_splits=10):\n",
    "    df = results_df.copy()\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    for index, (tr_ind, tset_ind) in enumerate(kf.split(X, y)):\n",
    "        print(\"Starting {i} fold out of {n} outher folds\".format(i=index,n=n_splits))\n",
    "        \n",
    "        X_train = X.iloc[tr_ind].copy()\n",
    "        y_train = y.iloc[tr_ind].copy()\n",
    "        \n",
    "        X_test = X.iloc[tset_ind].copy()\n",
    "        y_test = y.iloc[tset_ind].copy()\n",
    "        best_params, best_metrics, trials = inner_cv_hyperopt(X_train,y_train)\n",
    "        info = {'CV_fold':index,\n",
    "                'HP_vals':{k: best_params[k] for k in list(best_params)[:3]},\n",
    "                **best_metrics\n",
    "               }\n",
    "        record.update(info)\n",
    "        print(record)\n",
    "        df = df.append(record, ignore_index=True)\n",
    "        print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Dataset','Algorithm','CV_fold','HP_vals','Accuracy','TPR','FPR','Precision','AUC','PR-Curve','Training_time','Inference_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting on abalon dataset\n",
      "classification_datasets\\abalon.csv\n",
      "Starting 0 fold out of 10 outher folds\n",
      "Starting 0 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.71s/trial, best loss: -0.6520351157222666]\n",
      "Starting 1 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.12s/trial, best loss: -0.6464485235434956]\n",
      "Starting 2 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.24s/trial, best loss: -0.6536312849162011]\n",
      "{'Dataset': 'abalon', 'Algorithm': 'Catboost', 'CV_fold': 0, 'HP_vals': {'learning_rate': 0.36658561415688923, 'max_depth': 3, 'n_estimators': 6}, 'Accuracy': 0.6536312849162011, 'TPR': 0.15035833009959365, 'FPR': 0.5962650025175095, 'Precision': 0.6542445224200115, 'AUC': 0.8192226525324422, 'PR-Curve': 0.8028422151273712, 'Training_time': 5.195810500000334, 'Inference_time': 0.007196500000645756}\n",
      "  Dataset Algorithm CV_fold  \\\n",
      "0  abalon  Catboost       0   \n",
      "\n",
      "                                             HP_vals  Accuracy       TPR  \\\n",
      "0  {'learning_rate': 0.36658561415688923, 'max_de...  0.653631  0.150358   \n",
      "\n",
      "        FPR  Precision       AUC  PR-Curve  Training_time  Inference_time  \n",
      "0  0.596265   0.654245  0.819223  0.802842       5.195811        0.007197  \n",
      "Starting 1 fold out of 10 outher folds\n",
      "Starting 0 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.45s/trial, best loss: -0.6432561851556265]\n",
      "Starting 1 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.36s/trial, best loss: -0.6528332003192339]\n",
      "Starting 2 fold out of 3 inner folds\n",
      "100%|██████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.92s/trial, best loss: -0.644852354349561]\n",
      "{'Dataset': 'abalon', 'Algorithm': 'Catboost', 'CV_fold': 1, 'HP_vals': {'learning_rate': 0.41798969583433027, 'max_depth': 1, 'n_estimators': 3}, 'Accuracy': 0.644852354349561, 'TPR': 0.1370405049586704, 'FPR': 0.5685269366924043, 'Precision': 0.6418491473462631, 'AUC': 0.8190911853850253, 'PR-Curve': 0.806161887636173, 'Training_time': 0.6634736000005432, 'Inference_time': 0.002970699999423232}\n",
      "  Dataset Algorithm CV_fold  \\\n",
      "0  abalon  Catboost       0   \n",
      "1  abalon  Catboost       1   \n",
      "\n",
      "                                             HP_vals  Accuracy       TPR  \\\n",
      "0  {'learning_rate': 0.36658561415688923, 'max_de...  0.653631  0.150358   \n",
      "1  {'learning_rate': 0.41798969583433027, 'max_de...  0.644852  0.137041   \n",
      "\n",
      "        FPR  Precision       AUC  PR-Curve  Training_time  Inference_time  \n",
      "0  0.596265   0.654245  0.819223  0.802842       5.195811        0.007197  \n",
      "1  0.568527   0.641849  0.819091  0.806162       0.663474        0.002971  \n",
      "Starting 2 fold out of 10 outher folds\n",
      "Starting 0 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.90s/trial, best loss: -0.6344772545889864]\n",
      "Starting 1 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.54s/trial, best loss: -0.6408619313647247]\n",
      "Starting 2 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.33s/trial, best loss: -0.6568236233040702]\n",
      "{'Dataset': 'abalon', 'Algorithm': 'Catboost', 'CV_fold': 2, 'HP_vals': {'learning_rate': 0.41798969583433027, 'max_depth': 1, 'n_estimators': 3}, 'Accuracy': 0.6568236233040702, 'TPR': 0.14256338215074724, 'FPR': 0.5968285216937756, 'Precision': 0.6472500909931416, 'AUC': 0.8320747891319661, 'PR-Curve': 0.8173845339779691, 'Training_time': 1.336583299999802, 'Inference_time': 0.004061599999658938}\n",
      "  Dataset Algorithm CV_fold  \\\n",
      "0  abalon  Catboost       0   \n",
      "1  abalon  Catboost       1   \n",
      "2  abalon  Catboost       2   \n",
      "\n",
      "                                             HP_vals  Accuracy       TPR  \\\n",
      "0  {'learning_rate': 0.36658561415688923, 'max_de...  0.653631  0.150358   \n",
      "1  {'learning_rate': 0.41798969583433027, 'max_de...  0.644852  0.137041   \n",
      "2  {'learning_rate': 0.41798969583433027, 'max_de...  0.656824  0.142563   \n",
      "\n",
      "        FPR  Precision       AUC  PR-Curve  Training_time  Inference_time  \n",
      "0  0.596265   0.654245  0.819223  0.802842       5.195811        0.007197  \n",
      "1  0.568527   0.641849  0.819091  0.806162       0.663474        0.002971  \n",
      "2  0.596829   0.647250  0.832075  0.817385       1.336583        0.004062  \n",
      "Starting 3 fold out of 10 outher folds\n",
      "Starting 0 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.48s/trial, best loss: -0.6600159616919393]\n",
      "Starting 1 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.14s/trial, best loss: -0.6328810853950518]\n",
      "Starting 2 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.73s/trial, best loss: -0.6440542697525937]\n",
      "{'Dataset': 'abalon', 'Algorithm': 'Catboost', 'CV_fold': 3, 'HP_vals': {'learning_rate': 0.36658561415688923, 'max_depth': 3, 'n_estimators': 6}, 'Accuracy': 0.6440542697525937, 'TPR': 0.15347539847997624, 'FPR': 0.5894226653349505, 'Precision': 0.6344410750301581, 'AUC': 0.8185855635213385, 'PR-Curve': 0.8044110607067708, 'Training_time': 4.356114299999717, 'Inference_time': 0.005327400000169291}\n",
      "  Dataset Algorithm CV_fold  \\\n",
      "0  abalon  Catboost       0   \n",
      "1  abalon  Catboost       1   \n",
      "2  abalon  Catboost       2   \n",
      "3  abalon  Catboost       3   \n",
      "\n",
      "                                             HP_vals  Accuracy       TPR  \\\n",
      "0  {'learning_rate': 0.36658561415688923, 'max_de...  0.653631  0.150358   \n",
      "1  {'learning_rate': 0.41798969583433027, 'max_de...  0.644852  0.137041   \n",
      "2  {'learning_rate': 0.41798969583433027, 'max_de...  0.656824  0.142563   \n",
      "3  {'learning_rate': 0.36658561415688923, 'max_de...  0.644054  0.153475   \n",
      "\n",
      "        FPR  Precision       AUC  PR-Curve  Training_time  Inference_time  \n",
      "0  0.596265   0.654245  0.819223  0.802842       5.195811        0.007197  \n",
      "1  0.568527   0.641849  0.819091  0.806162       0.663474        0.002971  \n",
      "2  0.596829   0.647250  0.832075  0.817385       1.336583        0.004062  \n",
      "3  0.589423   0.634441  0.818586  0.804411       4.356114        0.005327  \n",
      "Starting 4 fold out of 10 outher folds\n",
      "Starting 0 fold out of 3 inner folds\n",
      "100%|██████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.69s/trial, best loss: -0.627294493216281]\n",
      "Starting 1 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.63s/trial, best loss: -0.6440542697525937]\n",
      "Starting 2 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.68s/trial, best loss: -0.6280925778132482]\n",
      "{'Dataset': 'abalon', 'Algorithm': 'Catboost', 'CV_fold': 4, 'HP_vals': {'learning_rate': 0.41798969583433027, 'max_depth': 1, 'n_estimators': 3}, 'Accuracy': 0.6280925778132482, 'TPR': 0.148668261653964, 'FPR': 0.5700664890099495, 'Precision': 0.6235254495693499, 'AUC': 0.8162904166846775, 'PR-Curve': 0.8055290658751767, 'Training_time': 0.8627717999997913, 'Inference_time': 0.004973299999619485}\n",
      "  Dataset Algorithm CV_fold  \\\n",
      "0  abalon  Catboost       0   \n",
      "1  abalon  Catboost       1   \n",
      "2  abalon  Catboost       2   \n",
      "3  abalon  Catboost       3   \n",
      "4  abalon  Catboost       4   \n",
      "\n",
      "                                             HP_vals  Accuracy       TPR  \\\n",
      "0  {'learning_rate': 0.36658561415688923, 'max_de...  0.653631  0.150358   \n",
      "1  {'learning_rate': 0.41798969583433027, 'max_de...  0.644852  0.137041   \n",
      "2  {'learning_rate': 0.41798969583433027, 'max_de...  0.656824  0.142563   \n",
      "3  {'learning_rate': 0.36658561415688923, 'max_de...  0.644054  0.153475   \n",
      "4  {'learning_rate': 0.41798969583433027, 'max_de...  0.628093  0.148668   \n",
      "\n",
      "        FPR  Precision       AUC  PR-Curve  Training_time  Inference_time  \n",
      "0  0.596265   0.654245  0.819223  0.802842       5.195811        0.007197  \n",
      "1  0.568527   0.641849  0.819091  0.806162       0.663474        0.002971  \n",
      "2  0.596829   0.647250  0.832075  0.817385       1.336583        0.004062  \n",
      "3  0.589423   0.634441  0.818586  0.804411       4.356114        0.005327  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  0.570066   0.623525  0.816290  0.805529       0.862772        0.004973  \n",
      "Starting 5 fold out of 10 outher folds\n",
      "Starting 0 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.04s/trial, best loss: -0.6400638467677574]\n",
      "Starting 1 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.76s/trial, best loss: -0.6392657621707901]\n",
      "Starting 2 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.11s/trial, best loss: -0.6496408619313647]\n",
      "{'Dataset': 'abalon', 'Algorithm': 'Catboost', 'CV_fold': 5, 'HP_vals': {'learning_rate': 0.36658561415688923, 'max_depth': 3, 'n_estimators': 6}, 'Accuracy': 0.6496408619313647, 'TPR': 0.1492639700166747, 'FPR': 0.5932848483781078, 'Precision': 0.6429406484125422, 'AUC': 0.8254066953562281, 'PR-Curve': 0.8110646824005935, 'Training_time': 4.5455111999999644, 'Inference_time': 0.006175299999995332}\n",
      "  Dataset Algorithm CV_fold  \\\n",
      "0  abalon  Catboost       0   \n",
      "1  abalon  Catboost       1   \n",
      "2  abalon  Catboost       2   \n",
      "3  abalon  Catboost       3   \n",
      "4  abalon  Catboost       4   \n",
      "5  abalon  Catboost       5   \n",
      "\n",
      "                                             HP_vals  Accuracy       TPR  \\\n",
      "0  {'learning_rate': 0.36658561415688923, 'max_de...  0.653631  0.150358   \n",
      "1  {'learning_rate': 0.41798969583433027, 'max_de...  0.644852  0.137041   \n",
      "2  {'learning_rate': 0.41798969583433027, 'max_de...  0.656824  0.142563   \n",
      "3  {'learning_rate': 0.36658561415688923, 'max_de...  0.644054  0.153475   \n",
      "4  {'learning_rate': 0.41798969583433027, 'max_de...  0.628093  0.148668   \n",
      "5  {'learning_rate': 0.36658561415688923, 'max_de...  0.649641  0.149264   \n",
      "\n",
      "        FPR  Precision       AUC  PR-Curve  Training_time  Inference_time  \n",
      "0  0.596265   0.654245  0.819223  0.802842       5.195811        0.007197  \n",
      "1  0.568527   0.641849  0.819091  0.806162       0.663474        0.002971  \n",
      "2  0.596829   0.647250  0.832075  0.817385       1.336583        0.004062  \n",
      "3  0.589423   0.634441  0.818586  0.804411       4.356114        0.005327  \n",
      "4  0.570066   0.623525  0.816290  0.805529       0.862772        0.004973  \n",
      "5  0.593285   0.642941  0.825407  0.811065       4.545511        0.006175  \n",
      "Starting 6 fold out of 10 outher folds\n",
      "Starting 0 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.20s/trial, best loss: -0.6225059856344772]\n",
      "Starting 1 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.28s/trial, best loss: -0.6392657621707901]\n",
      "Starting 2 fold out of 3 inner folds\n",
      "100%|██████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.56s/trial, best loss: -0.636073423782921]\n",
      "{'Dataset': 'abalon', 'Algorithm': 'Catboost', 'CV_fold': 6, 'HP_vals': {'learning_rate': 0.41798969583433027, 'max_depth': 1, 'n_estimators': 3}, 'Accuracy': 0.636073423782921, 'TPR': 0.14750163592930288, 'FPR': 0.5845712965826692, 'Precision': 0.6264753248691157, 'AUC': 0.8284563967139223, 'PR-Curve': 0.8132105973559476, 'Training_time': 1.9745708000000377, 'Inference_time': 0.011223600000448641}\n",
      "  Dataset Algorithm CV_fold  \\\n",
      "0  abalon  Catboost       0   \n",
      "1  abalon  Catboost       1   \n",
      "2  abalon  Catboost       2   \n",
      "3  abalon  Catboost       3   \n",
      "4  abalon  Catboost       4   \n",
      "5  abalon  Catboost       5   \n",
      "6  abalon  Catboost       6   \n",
      "\n",
      "                                             HP_vals  Accuracy       TPR  \\\n",
      "0  {'learning_rate': 0.36658561415688923, 'max_de...  0.653631  0.150358   \n",
      "1  {'learning_rate': 0.41798969583433027, 'max_de...  0.644852  0.137041   \n",
      "2  {'learning_rate': 0.41798969583433027, 'max_de...  0.656824  0.142563   \n",
      "3  {'learning_rate': 0.36658561415688923, 'max_de...  0.644054  0.153475   \n",
      "4  {'learning_rate': 0.41798969583433027, 'max_de...  0.628093  0.148668   \n",
      "5  {'learning_rate': 0.36658561415688923, 'max_de...  0.649641  0.149264   \n",
      "6  {'learning_rate': 0.41798969583433027, 'max_de...  0.636073  0.147502   \n",
      "\n",
      "        FPR  Precision       AUC  PR-Curve  Training_time  Inference_time  \n",
      "0  0.596265   0.654245  0.819223  0.802842       5.195811        0.007197  \n",
      "1  0.568527   0.641849  0.819091  0.806162       0.663474        0.002971  \n",
      "2  0.596829   0.647250  0.832075  0.817385       1.336583        0.004062  \n",
      "3  0.589423   0.634441  0.818586  0.804411       4.356114        0.005327  \n",
      "4  0.570066   0.623525  0.816290  0.805529       0.862772        0.004973  \n",
      "5  0.593285   0.642941  0.825407  0.811065       4.545511        0.006175  \n",
      "6  0.584571   0.626475  0.828456  0.813211       1.974571        0.011224  \n",
      "Starting 7 fold out of 10 outher folds\n",
      "Starting 0 fold out of 3 inner folds\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.88s/trial, best loss: -0.6435406698564593]\n",
      "Starting 1 fold out of 3 inner folds\n",
      " 50%|████████████████████████▌                        | 1/2 [00:01<00:01,  1.17s/trial, best loss: -0.6400638467677574]"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "for cls_dataset in glob.glob('classification_datasets/*.csv'): \n",
    "    print(\"Fitting on {f} dataset\".format(f=Path(cls_dataset).stem))\n",
    "    print(cls_dataset)\n",
    "    record = {'Dataset':Path(cls_dataset).stem,'Algorithm':'Catboost'}\n",
    "    df = pd.read_csv(cls_dataset)\n",
    "    X = df[df.columns[:-1]]\n",
    "    y = df[df.columns[-1]]\n",
    "    results_df = outer_cv(X,y, results_df,record)\n",
    "    print(results_df)\n",
    "    results_df.to_csv('catboost-results.csv',index=False)\n",
    "    break\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
