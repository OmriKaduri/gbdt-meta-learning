{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lior\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import glob\n",
    "from sklearn.model_selection import cross_validate\n",
    "import hyperopt\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from pystacknet.pystacknet import StackNetClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def fpr_tpr(y_true, y_pred):\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "\n",
    "    fpr = fp / (fp + tn)\n",
    "    tpr = tp / (tp + fn) #Precision\n",
    "    \n",
    "    return fpr, tpr\n",
    "\n",
    "\n",
    "def fpr_tpr_for_threshold(y_true, y_pred_probs, threshold=.5):\n",
    "    n_classes = np.unique(y_true)\n",
    "    num_paires = (len(n_classes) * (len(n_classes) - 1)) // 2\n",
    "    fpr_scores = np.zeros(num_paires)\n",
    "    tpr_scores = np.zeros(num_paires)\n",
    "    for ix, (a, b) in enumerate(combinations(n_classes, 2)): # one vs one\n",
    "        a_mask = y_true == a\n",
    "        b_mask = y_true == b\n",
    "        ab_mask = np.logical_or(a_mask, b_mask)\n",
    "\n",
    "        a_true = a_mask[ab_mask]\n",
    "        b_true = b_mask[ab_mask]\n",
    "\n",
    "        y_pred_a = np.where(y_pred_probs[ab_mask, a] >= threshold, 1, 0)\n",
    "        y_pred_b = np.where(y_pred_probs[ab_mask, b] >= threshold, 1, 0)\n",
    "\n",
    "        fpr_a, tpr_a = fpr_tpr(a_true, y_pred_a)\n",
    "        fpr_b, tpr_b = fpr_tpr(b_true, y_pred_b)\n",
    "        fpr_scores[ix] = (fpr_a + fpr_b) / 2\n",
    "        tpr_scores[ix] = (tpr_a + tpr_b) / 2\n",
    "        \n",
    "    return np.average(fpr_scores), np.average(tpr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_precision_recall_curve(y_true, y_pred_probs):\n",
    "    n_classes = np.unique(y_true)\n",
    "    num_paires = (len(n_classes) * (len(n_classes) - 1)) // 2\n",
    "    ap_scores = np.zeros(num_paires)\n",
    "    \n",
    "    for ix, (a, b) in enumerate(combinations(n_classes, 2)): # one vs one\n",
    "        a_mask = y_true == a\n",
    "        b_mask = y_true == b\n",
    "        ab_mask = np.logical_or(a_mask, b_mask)\n",
    "\n",
    "        a_true = a_mask[ab_mask]\n",
    "        b_true = b_mask[ab_mask]\n",
    "        \n",
    "        a_ap = average_precision_score(a_true, y_pred_probs[ab_mask, a])\n",
    "        b_ap = average_precision_score(b_true, y_pred_probs[ab_mask, b])\n",
    "        ap_scores[ix] = (a_ap + b_ap) / 2\n",
    "        \n",
    "    return np.average(ap_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, X_test, y_test, is_multiclass):\n",
    "    infer_start = timer()\n",
    "    test_preds_proba = model.predict_proba(X_test)\n",
    "    test_preds = np.argmax(test_preds_proba, axis=1)\n",
    "    infer_end = timer()\n",
    "    infer_time = infer_end - infer_start #For all dataset\n",
    "    infer_time_per_1000 = (infer_time / X_test.shape[0])*1000\n",
    "\n",
    "    fpr, tpr = fpr_tpr_for_threshold(y_test, test_preds_proba)\n",
    "#     is_multiclass = len(np.unique(y_test)) > 2\n",
    "    if is_multiclass:\n",
    "        auc = roc_auc_score(y_test,test_preds_proba, multi_class='ovr', average='macro') \n",
    "        precision = precision_score(y_test, test_preds, average='macro')\n",
    "        pr_curve = multiclass_precision_recall_curve(y_test, test_preds_proba) # Macro avg\n",
    "    else:\n",
    "        test_preds_proba = np.max(test_preds_proba,axis=1)\n",
    "        auc = roc_auc_score(y_test,test_preds_proba)\n",
    "        precision = precision_score(y_test, test_preds)\n",
    "        pr_curve = average_precision_score(y_test, test_preds_proba)\n",
    "        \n",
    "\n",
    "    return {'Accuracy':accuracy_score(y_test, test_preds),\n",
    "            'TPR':tpr, #macro average\n",
    "            'FPR':fpr, #macro average\n",
    "            'Precision': precision,\n",
    "            'AUC': auc,\n",
    "            'PR-Curve': pr_curve,\n",
    "            'Inference_time':infer_time_per_1000\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, precision_score, roc_auc_score, roc_curve\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class HyperoptObjective(object):\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, model, const_params, is_multiclass):\n",
    "        self.evaluated_count = 0\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.model = model\n",
    "        self.is_multiclass = is_multiclass\n",
    "        self.constant_params = const_params\n",
    "        if self.y_train.dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            self.y_train = le.fit_transform(self.y_train)\n",
    "            self.y_test = le.fit_transform(self.y_test)\n",
    "            \n",
    "        \n",
    "    '''\n",
    "    The way that HyperOpt fmin function works, is that on each evaluation \n",
    "    it calls given objective function. \n",
    "    Since we decided to declare our objective as class instead of a function,\n",
    "    we will implement the evaluation logic inside the __call__ method.\n",
    "    '''\n",
    "    def __call__(self, hyper_params):\n",
    "        \n",
    "        models=[ \n",
    "        ######## First level ########\n",
    "        [RandomForestClassifier (n_estimators=hyper_params['RandomForestClassifier_est_1'], criterion=\"entropy\", \n",
    "                                 max_depth=5, max_features=0.5, random_state=1),\n",
    "         ExtraTreesClassifier (n_estimators=hyper_params['ExtraTreesClassifier_est'], criterion=\"entropy\",\n",
    "                               max_depth=5, max_features=0.5, random_state=1),\n",
    "         GradientBoostingClassifier(n_estimators=hyper_params['GradientBoostingClassifier_est'], learning_rate=0.1, \n",
    "                                    max_depth=5, max_features=0.5, random_state=1)\n",
    "         ],\n",
    "        ######## Second level ########\n",
    "        [RandomForestClassifier (n_estimators=hyper_params['RandomForestClassifier_est_2'], criterion=\"entropy\",\n",
    "                                 max_depth=5, max_features=0.5, random_state=1)]\n",
    "        ]\n",
    "        \n",
    "        del hyper_params['RandomForestClassifier_est_1']\n",
    "        del hyper_params['ExtraTreesClassifier_est']\n",
    "        del hyper_params['GradientBoostingClassifier_est']\n",
    "        del hyper_params['RandomForestClassifier_est_2']\n",
    "        \n",
    "        model = self.model(models, **hyper_params, **self.constant_params)\n",
    "        fit_start = timer()\n",
    "        print(\"self.X_train.shape = \",self.X_train.shape)\n",
    "        print(\"self.y_train.shape = \",self.y_train.shape)\n",
    "        model.fit(X=self.X_train,y=self.y_train)\n",
    "        fit_end = timer()\n",
    "        fit_time = fit_end - fit_start\n",
    "\n",
    "        self.evaluated_count += 1\n",
    "        metrics = evaluate_metrics(model, self.X_test, self.y_test, self.is_multiclass)\n",
    "#         print(\"Inner AUC:\",metrics['AUC'])\n",
    "#         print(\"Inner Accuracy:\",metrics['Accuracy'])\n",
    "\n",
    "        return {\n",
    "                'loss':-metrics['AUC'],\n",
    "                'status':STATUS_OK,\n",
    "                'fit_time':fit_time,\n",
    "                'model':model\n",
    "            }\n",
    "            #NOTE: The negative sign is due to that fact that we optimize for accuracy,\n",
    "              #therefore we want to minimize the negative acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import space_eval\n",
    "\n",
    "def find_best_params(X_train, \n",
    "                     y_train,   \n",
    "                     X_test,\n",
    "                     y_test,\n",
    "                     model,\n",
    "                     const_params, \n",
    "                     parameter_space,\n",
    "                     max_evals=25,\n",
    "                    ):\n",
    "    \n",
    "    objective = HyperoptObjective(X_train, y_train, X_test, y_test, model, const_params, is_multiclass)\n",
    "    '''\n",
    "    HyperOpt Trials object stores details of every iteration. \n",
    "    https://github.com/hyperopt/hyperopt/wiki/FMin#12-attaching-extra-information-via-the-trials-object\n",
    "    '''\n",
    "    trials = hyperopt.Trials()\n",
    "    \n",
    "    '''\n",
    "    Hyperopt fmin function returns only parameters from the search space.\n",
    "    Therefore, before returning best_params\n",
    "    we will merge best_params with the const params, \n",
    "    so we have all parameters in one place for training the best model.\n",
    "    '''\n",
    "    best_params = hyperopt.fmin(\n",
    "        fn=objective,\n",
    "        space=parameter_space,\n",
    "        algo=hyperopt.tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        trials=trials\n",
    "    )\n",
    "    best_params = space_eval(parameter_space, best_params)\n",
    "    best_params.update(const_params)\n",
    "    \n",
    "    return best_params, trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_cv_hyperopt(X,y, n_splits=3):\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    parameter_space = {\n",
    "        'restacking': hyperopt.hp.choice('restacking', [True, False]),\n",
    "        'use_retraining': hyperopt.hp.choice('use_retraining', [True, False]),\n",
    "        'RandomForestClassifier_est_1': hyperopt.hp.choice('RandomForestClassifier_est_1', list(range(100, 500, 50))),\n",
    "        'RandomForestClassifier_est_2': hyperopt.hp.choice('RandomForestClassifier_est_2', list(range(100, 500, 50))),\n",
    "        'ExtraTreesClassifier_est': hyperopt.hp.choice('ExtraTreesClassifier_est', list(range(100, 500, 50))),\n",
    "        'GradientBoostingClassifier_est': hyperopt.hp.choice('GradientBoostingClassifier_est', list(range(100, 500, 50))),\n",
    "    }\n",
    "    best_auc = 0\n",
    "    \n",
    "    for index, (tr_ind, test_ind) in enumerate(kf.split(X,y)):\n",
    "#         print(\"Starting {i} fold out of {n} inner folds\".format(i=index,n=n_splits))\n",
    "        \n",
    "        X_train = X.iloc[tr_ind].copy()\n",
    "        y_train = y[tr_ind]\n",
    "        \n",
    "        X_test = X.iloc[test_ind].copy()\n",
    "        y_test = y[test_ind]\n",
    "        (n_data, input_dim) = X_train.shape\n",
    "        \n",
    "        const_params = {\n",
    "            'n_jobs': -1,\n",
    "            'random_state': 1,\n",
    "            'use_proba': True,\n",
    "            'folds': 2,\n",
    "            'metric': 'accuracy',\n",
    "            'verbose': 0\n",
    "            \n",
    "        }\n",
    "        \n",
    "        curr_best_params, trials = find_best_params(\n",
    "            X_train, \n",
    "            y_train, \n",
    "            X_test,\n",
    "            y_test,\n",
    "            StackNetClassifier,\n",
    "            const_params,\n",
    "            parameter_space,\n",
    "            max_evals=50,\n",
    "        )\n",
    "        # 2\n",
    "        fnvals = [(t['result']) for t in trials.trials]\n",
    "        params = max(fnvals, key=lambda x: x['loss'])\n",
    "        if -params['loss'] > best_auc:\n",
    "            best_auc = -params['loss']\n",
    "            fit_time = params['fit_time']\n",
    "            best_params = curr_best_params\n",
    "            model = params['model']\n",
    "            trials = trials\n",
    "            \n",
    "    return best_params, trials, fit_time, model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_cv(X, y, results_df, record, is_multiclass, n_splits=10):\n",
    "    df = results_df.copy()\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "#     is_multiclass = len(np.unique(y)) > 2\n",
    "    \n",
    "    for index, (tr_ind, tset_ind) in enumerate(kf.split(X, y)):\n",
    "        print(\"Starting {i} fold out of {n} outher folds\".format(i=index,n=n_splits))\n",
    "        \n",
    "        X_train = X.iloc[tr_ind].copy()\n",
    "        y_train = y[tr_ind]\n",
    "        \n",
    "        X_test = X.iloc[tset_ind].copy()\n",
    "        y_test = y[tset_ind]\n",
    "        best_params, trials, fit_time, model = inner_cv_hyperopt(X_train,y_train)\n",
    "        best_metrics = evaluate_metrics(model, X_test, y_test, is_multiclass)\n",
    "        best_metrics['Training_time'] = fit_time\n",
    "        info = {'CV_fold':index,\n",
    "                'HP_vals':{k: best_params[k] for k in list(best_params)[:3]},\n",
    "                **best_metrics\n",
    "               }\n",
    "        record.update(info)\n",
    "        df = df.append(record, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting on analcatdata_germangss dataset\n",
      "Starting 0 fold out of 10 outher folds\n",
      "self.X_train.shape =                                                                                                                                                                                                                   \n",
      "(240, 17)                                                                                                                                                                                                                              \n",
      "self.y_train.shape =                                                                                                                                                                                                                   \n",
      "(240,)                                                                                                                                                                                                                                 \n",
      "  0%|                                                                                                                                                                                           | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lior\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "c:\\users\\lior\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "job exception: Output dimensionality among folds is not consistent as 129!=99 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                           | 0/50 [00:24<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Output dimensionality among folds is not consistent as 129!=99 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9b01055a54f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0my_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mresults_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mouter_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_transformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multiclass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mresults_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRESULTS_FILENAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-8d56b0d76591>\u001b[0m in \u001b[0;36mouter_cv\u001b[1;34m(X, y, results_df, record, is_multiclass, n_splits)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtset_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtset_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mbest_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner_cv_hyperopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mbest_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multiclass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mbest_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Training_time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-fbcd1df826d3>\u001b[0m in \u001b[0;36minner_cv_hyperopt\u001b[1;34m(X, y, n_splits)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mconst_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mparameter_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         )\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-667ea7adb20e>\u001b[0m in \u001b[0;36mfind_best_params\u001b[1;34m(X_train, y_train, X_test, y_test, model, const_params, parameter_space, max_evals)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     )\n\u001b[0;32m     33\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspace_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameter_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lior\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m         )\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lior\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m         )\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lior\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lior\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lior\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    284\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lior\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lior\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             )\n\u001b[1;32m--> 894\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-d3546904895a>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, hyper_params)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"self.X_train.shape = \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"self.y_train.shape = \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0mfit_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_end\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_start\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lior\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pystacknet-0.0.1-py3.6.egg\\pystacknet\\pystacknet.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_level_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mpreds_concat_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Output dimensionality among folds is not consistent as %d!=%d \"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_level_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreds_concat_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m                 \u001b[0mtrain_oof\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds_concat_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Output dimensionality among folds is not consistent as 129!=99 "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sklearn import preprocessing\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Dataset','Algorithm','CV_fold','HP_vals','Accuracy','TPR','FPR','Precision','AUC','PR-Curve','Training_time','Inference_time'])\n",
    "RESULTS_FILENAME = \"pystacknet_results.csv\"\n",
    "results_file = Path(RESULTS_FILENAME)\n",
    "if results_file.is_file():\n",
    "    results_df = pd.read_csv(RESULTS_FILENAME)\n",
    "\n",
    "for cls_dataset in glob.glob('classification_datasets/*.csv')[6:]: \n",
    "    dataset_name = Path(cls_dataset).stem\n",
    "    if dataset_name in results_df.Dataset.unique():\n",
    "        print(\"Skipping already fitted dataset: {f}\".format(f=dataset_name))\n",
    "        continue\n",
    "    print(\"Fitting on {f} dataset\".format(f=dataset_name))\n",
    "    record = {'Dataset':dataset_name,'Algorithm':'Catboost'}\n",
    "    df = pd.read_csv(cls_dataset)\n",
    "    X = pd.get_dummies(df[df.columns[:-1]])\n",
    "    y = df[df.columns[-1]]\n",
    "    is_multiclass = len(np.unique(y)) > 2\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_transformed = le.fit_transform(y)\n",
    "    \n",
    "    results_df = outer_cv(X,y_transformed, results_df,record, is_multiclass)\n",
    "    results_df.to_csv(RESULTS_FILENAME,index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
